"""
+------------------------------+------------------+----------+
| Description | Published Date | Victim's Website | Post URL |
+------------------------------+------------------+----------+
|      X      |        X       |                  |          |
+------------------------------+------------------+----------+
Rappel : def appender(post_title, group_name, description="", website="", published="", post_url=""):
"""
import os
from bs4 import BeautifulSoup
import json
import html
from sharedutils import errlog
from parse import appender 
import datetime
import re

def main():
    for filename in os.listdir('source'):
        #try:
            if filename.startswith('akira_leak-'):
                html_doc='source/'+filename
                file=open(html_doc, 'r')
                soup=BeautifulSoup(file,'html.parser')
                jsonpart = soup.pre.contents
                data = json.loads(jsonpart[0])
                for entry in data:
                    title = html.unescape(entry['name'])
                    description = entry['desc']
                    url = entry['url']
                    pattern = r'\[\[!;;;;(.*?)\]'
                    match = re.search(pattern, url)
                    if match:
                        url = match.group(1)
                    else:
                        url =''
                    appender(title.replace('\n',''), 'akira', description.replace('\n',''),'','',url)
                file.close()
        #except:
            #errlog('akira_leak: ' + 'parsing fail')
            #pass    
